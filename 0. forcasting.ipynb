{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and packages / Define needed functions / Call the whole path of required csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import os\n",
    "\n",
    "from scipy.stats import boxcox, norm\n",
    "from scipy.stats import laplace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import norm\n",
    "from scipy.special import gamma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "TRAINING_PATH = os.path.join(os.getcwd(), \"1-1. train_y.csv\")\n",
    "SUBMISSION_PATH = os.path.join(os.getcwd(), \"2. submission_format.csv\")\n",
    "\n",
    "GJ_LDAPS_TRAIN_PATH = os.path.join(os.getcwd(), \"1-4. train_ldaps_gyeongju.pkl\")\n",
    "GJ_LDAPS_TEST_PATH = os.path.join(os.getcwd(), \"1-4. test_ldaps_gyeongju.pkl\")\n",
    "\n",
    "YG_LDAPS_TRAIN_PATH = os.path.join(os.getcwd(), \"1-3. train_ldaps_yeonggwang.pkl\")\n",
    "YG_LDAPS_TEST_PATH = os.path.join(os.getcwd(), \"1-3. test_ldaps_yeonggwang.pkl\")\n",
    "\n",
    "GJ_SCADA_2020_PATH = os.path.join(os.getcwd(), \"dynamic_report_ewp02_2020_10min.xlsx\")\n",
    "GJ_SCADA_2021_PATH = os.path.join(os.getcwd(), \"dynamic_report_ewp02_2021_10min.xlsx\")\n",
    "GJ_SCADA_2022_PATH = os.path.join(os.getcwd(), \"dynamic_report_ewp02_2022_10min.xlsx\")\n",
    "\n",
    "YG_SCADA_2007_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202001_202007.xlsx\")\n",
    "YG_SCADA_2012_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202008_202012.xlsx\")\n",
    "YG_SCADA_2106_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202101_202106.xlsx\")\n",
    "YG_SCADA_2112_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202107_202112.xlsx\")\n",
    "YG_SCADA_2206_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202201_202206.xlsx\")\n",
    "YG_SCADA_2212_PATH = os.path.join(os.getcwd(),\"dynamic_report_ewp004_202207_202212.xlsx\")\n",
    "\n",
    "\n",
    "# function to Convert u, v vector to wind speed and direction.\n",
    "def uv_to_wsd(u_wind_speed, v_wind_speed):\n",
    "    u_ws = u_wind_speed.to_numpy()\n",
    "    v_ws = v_wind_speed.to_numpy()\n",
    "\n",
    "    # NOTE: http://colaweb.gmu.edu/dev/clim301/lectures/wind/wind-uv\n",
    "    wind_speed = np.nansum([u_ws**2, v_ws**2], axis=0)**(1/2.)\n",
    "\n",
    "    # math degree\n",
    "    wind_direction = np.rad2deg(np.arctan2(v_ws, u_ws+1e-6))\n",
    "    wind_direction[wind_direction < 0] += 360\n",
    "\n",
    "    # meteorological degree\n",
    "    wind_direction = 270 - wind_direction\n",
    "    wind_direction[wind_direction < 0] += 360\n",
    "\n",
    "    return wind_speed, wind_direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate the data into required form for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ldaps_manipulate(data):\n",
    "    data_return = data\n",
    "    data_return[\"wind_speed\"], data_return[\"wind_direction\"] = uv_to_wsd(data_return[\"wind_u_10m\"], data_return[\"wind_v_10m\"])\n",
    "    data_return['density']=data_return['pressure']*(0.029)/(8.314*data_return['temp_air'])\n",
    "    data_return['without_c']=(1/8000)*data_return['density']*np.pi*113*113*(data_return['wind_speed']**3)\n",
    "    data_return['Date']=pd.to_datetime(data_return.index)\n",
    "    \n",
    "    return data_return\n",
    "\n",
    "def train_y_manipulate(data, train_y, train_date, windfarm): # name of the windfarm 영광풍력 or 경주풍력\n",
    "    data_return = data\n",
    "    data_return=train_y[train_y['plant_name'] == windfarm]\n",
    "    data_return['end_datetime']=pd.to_datetime(data_return['end_datetime'])\n",
    "    data_return=data_return[data_return['end_datetime'].isin(train_date)]\n",
    "\n",
    "    return data_return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate train_data, test_data, match data for Yeonggwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/1479586426.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_return['end_datetime']=pd.to_datetime(data_return['end_datetime'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nall_data = []\\n\\nfor i in range(35):\\n    check201 = pd.read_excel(YG_SCADA_2007_PATH,  sheet_name=i, skiprows=5)\\n    check202 = pd.read_excel(YG_SCADA_2012_PATH,  sheet_name=i, skiprows=5)\\n    check211 = pd.read_excel(YG_SCADA_2106_PATH,  sheet_name=i, skiprows=5)\\n    check212 = pd.read_excel(YG_SCADA_2112_PATH,  sheet_name=i, skiprows=5)\\n    check221 = pd.read_excel(YG_SCADA_2206_PATH,  sheet_name=i, skiprows=5)\\n    check222 = pd.read_excel(YG_SCADA_2212_PATH,  sheet_name=i, skiprows=5)\\n\\n    check201 = check201[check201[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check202 = check202[check202[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check211 = check211[check211[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check212 = check212[check212[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check221 = check221[check221[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check222 = check222[check222[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n\\n    all_data.extend([check201, check202, check211, check212, check221, check222])\\n\\nyg_concat = pd.concat(all_data, ignore_index=True)\\n\\nyg_concat[\"Date/Time\"] = pd.to_datetime(yg_concat[\"Date/Time\"], errors=\"coerce\")\\n\\nyg_concat.rename(columns={\"Date/Time\": \"Date\"}, inplace=True)\\nyg_concat.rename(columns={\"WTG. Name\": \"turbine_id\"},inplace=True)\\nyg_concat.rename(columns={\"Rotor\\nPitch 1 Angle\\n[deg]\": \"state\"},inplace =True )\\n\\nyg_concat[\"Date\"] = pd.to_datetime(yg_concat[\"Date\"], format=\"%Y.%m.%d %H:%M\", errors=\"coerce\")\\nyg_concat[\"Date\"] = yg_concat[\"Date\"].dt.tz_localize(pytz.FixedOffset(540)) # Localize to timezone +09:00\\n\\n\\nyg_match_data = pd.merge(yg_concat, yg_train_x, on=[\"Date\", \"turbine_id\"], how=\"right\")\\nyg_match_data.to_csv(\"yg_match_data.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Yeonggwang data\n",
    "train_y = pd.read_csv(TRAINING_PATH)\n",
    "\n",
    "yg_train_x = pd.read_pickle(YG_LDAPS_TRAIN_PATH)\n",
    "yg_train_x = ldaps_manipulate(yg_train_x)\n",
    "yg_train_date=yg_train_x[yg_train_x['turbine_id']=='WTG01'].index\n",
    "\n",
    "yg_test = pd.read_pickle(YG_LDAPS_TEST_PATH)\n",
    "yg_test = ldaps_manipulate(yg_test)\n",
    "\n",
    "yg_train_y= pd.read_csv(TRAINING_PATH)\n",
    "yg_train_y = train_y_manipulate(yg_train_y, train_y, yg_train_date, \"영광풍력\") \n",
    "\n",
    "# Skip the process of manipulating and writing the file\n",
    "# Instead just read the file that was written\n",
    "YG_MATCH_PATH = os.path.join(os.getcwd(), \"yg_match_data.csv\")\n",
    "yg_match_data = pd.read_csv(YG_MATCH_PATH)\n",
    "\n",
    "\"\"\"\n",
    "all_data = []\n",
    "\n",
    "for i in range(35):\n",
    "    check201 = pd.read_excel(YG_SCADA_2007_PATH,  sheet_name=i, skiprows=5)\n",
    "    check202 = pd.read_excel(YG_SCADA_2012_PATH,  sheet_name=i, skiprows=5)\n",
    "    check211 = pd.read_excel(YG_SCADA_2106_PATH,  sheet_name=i, skiprows=5)\n",
    "    check212 = pd.read_excel(YG_SCADA_2112_PATH,  sheet_name=i, skiprows=5)\n",
    "    check221 = pd.read_excel(YG_SCADA_2206_PATH,  sheet_name=i, skiprows=5)\n",
    "    check222 = pd.read_excel(YG_SCADA_2212_PATH,  sheet_name=i, skiprows=5)\n",
    "\n",
    "    check201 = check201[check201[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check202 = check202[check202[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check211 = check211[check211[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check212 = check212[check212[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check221 = check221[check221[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check222 = check222[check222[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "\n",
    "    all_data.extend([check201, check202, check211, check212, check221, check222])\n",
    "\n",
    "yg_concat = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "yg_concat[\"Date/Time\"] = pd.to_datetime(yg_concat[\"Date/Time\"], errors=\"coerce\")\n",
    "\n",
    "yg_concat.rename(columns={\"Date/Time\": \"Date\"}, inplace=True)\n",
    "yg_concat.rename(columns={\"WTG. Name\": \"turbine_id\"},inplace=True)\n",
    "yg_concat.rename(columns={\"Rotor\\nPitch 1 Angle\\n[deg]\": \"state\"},inplace =True )\n",
    "\n",
    "yg_concat[\"Date\"] = pd.to_datetime(yg_concat[\"Date\"], format=\"%Y.%m.%d %H:%M\", errors=\"coerce\")\n",
    "yg_concat[\"Date\"] = yg_concat[\"Date\"].dt.tz_localize(pytz.FixedOffset(540)) # Localize to timezone +09:00\n",
    "\n",
    "\n",
    "yg_match_data = pd.merge(yg_concat, yg_train_x, on=[\"Date\", \"turbine_id\"], how=\"right\")\n",
    "yg_match_data.to_csv(\"yg_match_data.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate train_data, test_data, match data for Gyeongju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/1479586426.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_return['end_datetime']=pd.to_datetime(data_return['end_datetime'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nall_data2 = []\\n\\nfor i in range(9):\\n    check201 = pd.read_excel(GJ_SCADA_2020_PATH,  sheet_name=i, skiprows=5)\\n    check211 = pd.read_excel(GJ_SCADA_2021_PATH,  sheet_name=i, skiprows=5)\\n    check221 = pd.read_excel(GJ_SCADA_2022_PATH,  sheet_name=i, skiprows=5)\\n\\n    check201 = check201[check201[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check211 = check211[check211[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n    check221 = check221[check221[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\\n\\n    all_data2.extend([check201, check211, check221])\\n\\ngj_concat = pd.concat(all_data2, ignore_index=True)\\n\\ngj_concat[\"Date/Time\"] = pd.to_datetime(gj_concat[\"Date/Time\"], errors=\"coerce\")\\n\\ngj_concat.rename(columns={\"Date/Time\": \"Date\"}, inplace=True)\\ngj_concat.rename(columns={\"WTG. Name\": \"turbine_id\"},inplace=True)\\ngj_concat.rename(columns={\"Rotor\\nPitch 1 Angle\\n[deg]\": \"state\"},inplace =True )\\n\\ngj_concat[\"Date\"] = pd.to_datetime(gj_concat[\"Date\"], format=\"%Y.%m.%d %H:%M\", errors=\"coerce\")\\ngj_concat[\"Date\"] = gj_concat[\"Date\"].dt.tz_localize(pytz.FixedOffset(540)) # Localize to timezone +09:00\\n\\ngj_match_data = pd.merge(gj_concat, gj_train_x, on=[\"Date\", \"turbine_id\"], how=\"right\")\\ngj_match_data.to_csv(\"gj_match_data.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Gyeongju data\n",
    "train_y = pd.read_csv(TRAINING_PATH)\n",
    "\n",
    "gj_train_x = pd.read_pickle(GJ_LDAPS_TRAIN_PATH)\n",
    "gj_train_x = ldaps_manipulate(gj_train_x)\n",
    "gj_train_date=gj_train_x[gj_train_x['turbine_id']=='WTG01'].index\n",
    "\n",
    "gj_test = pd.read_pickle(GJ_LDAPS_TEST_PATH)\n",
    "gj_test = ldaps_manipulate(gj_test)\n",
    "\n",
    "gj_train_y= pd.read_csv(TRAINING_PATH)\n",
    "gj_train_y = train_y_manipulate(gj_train_y, train_y, gj_train_date, \"경주풍력\") \n",
    "\n",
    "# Skip the process of manipulating and writing the file\n",
    "# Instead just read the file that was written\n",
    "GJ_MATCH_PATH = os.path.join(os.getcwd(), \"gj_match_data.csv\")\n",
    "gj_match_data = pd.read_csv(GJ_MATCH_PATH)\n",
    "\n",
    "\"\"\"\n",
    "all_data2 = []\n",
    "\n",
    "for i in range(9):\n",
    "    check201 = pd.read_excel(GJ_SCADA_2020_PATH,  sheet_name=i, skiprows=5)\n",
    "    check211 = pd.read_excel(GJ_SCADA_2021_PATH,  sheet_name=i, skiprows=5)\n",
    "    check221 = pd.read_excel(GJ_SCADA_2022_PATH,  sheet_name=i, skiprows=5)\n",
    "\n",
    "    check201 = check201[check201[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check211 = check211[check211[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "    check221 = check221[check221[\"WTG. Name\"]==f\"WTG{i+1:02}\"]\n",
    "\n",
    "    all_data2.extend([check201, check211, check221])\n",
    "\n",
    "gj_concat = pd.concat(all_data2, ignore_index=True)\n",
    "\n",
    "gj_concat[\"Date/Time\"] = pd.to_datetime(gj_concat[\"Date/Time\"], errors=\"coerce\")\n",
    "\n",
    "gj_concat.rename(columns={\"Date/Time\": \"Date\"}, inplace=True)\n",
    "gj_concat.rename(columns={\"WTG. Name\": \"turbine_id\"},inplace=True)\n",
    "gj_concat.rename(columns={\"Rotor\\nPitch 1 Angle\\n[deg]\": \"state\"},inplace =True )\n",
    "\n",
    "gj_concat[\"Date\"] = pd.to_datetime(gj_concat[\"Date\"], format=\"%Y.%m.%d %H:%M\", errors=\"coerce\")\n",
    "gj_concat[\"Date\"] = gj_concat[\"Date\"].dt.tz_localize(pytz.FixedOffset(540)) # Localize to timezone +09:00\n",
    "\n",
    "gj_match_data = pd.merge(gj_concat, gj_train_x, on=[\"Date\", \"turbine_id\"], how=\"right\")\n",
    "gj_match_data.to_csv(\"gj_match_data.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a model for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining beta function that will be used on the prediction model\n",
    "def beta_function(alpha, beta):\n",
    "    return gamma(alpha) * gamma(beta) / gamma(alpha + beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE PREDICTION MODEL\n",
    "def forecasting(location):\n",
    "    if location == \"영광풍력\":\n",
    "        locat = \"영광풍력\"\n",
    "        match_data = yg_match_data\n",
    "        train_data = yg_train_y\n",
    "        test_data = yg_test\n",
    "\n",
    "    else:\n",
    "        locat = \"경주풍력\"\n",
    "        match_data = gj_match_data\n",
    "        train_data = gj_train_y\n",
    "        test_data = gj_test\n",
    "\n",
    "    binary_data = match_data[-match_data['state'].isna()]\n",
    "    binary_data['binary_state'] = 1*(binary_data['state']>=45)\n",
    "\n",
    "\n",
    "    print(\"@@@@@ Transfoming Data @@@@@@\")\n",
    "\n",
    "    transformed_data, lambd=boxcox(np.array(binary_data[binary_data['binary_state']==0]['wind_speed']))\n",
    "    mean_val=np.mean(transformed_data)\n",
    "    var_val=np.var(transformed_data)\n",
    "      \n",
    "    q=sum(binary_data['binary_state']==0)/len(binary_data)\n",
    "    \n",
    "    transformed_data2, lambd2=boxcox(np.array(binary_data['wind_speed']))\n",
    "    mean_val2=np.mean(transformed_data2)\n",
    "    var_val2=np.var(transformed_data2)\n",
    "       \n",
    "    #in test data\n",
    "\n",
    "    test_trans_data=(test_data['wind_speed']**lambd-1)/lambd\n",
    "    p=norm.pdf(test_trans_data,loc=mean_val, scale=np.sqrt(var_val))\n",
    "    test_trans_data2=(test_data['wind_speed']**lambd2-1)/lambd2\n",
    "    r=norm.pdf(test_trans_data2,loc=mean_val2,scale=np.sqrt(var_val2))\n",
    "    \n",
    "    test_data['proba_0']=p*q/r\n",
    "    test_data['no_c_with_proba']=test_data['proba_0']*test_data['without_c']\n",
    "\n",
    "\n",
    "    print(\"@@@@@ Scaling Data @@@@@@\")\n",
    "\n",
    "    #diff scaling\n",
    "    real_diff=train_data['energy_kwh'].diff(1)[1:]\n",
    "    test_diff = test_data.groupby('Date')['no_c_with_proba'].sum().diff(1)[1:]\n",
    "\n",
    "    loc2, scale2 = laplace.fit(real_diff)\n",
    "    loc3, scale3 = laplace.fit(test_diff)\n",
    "\n",
    "    test_diffs=loc2+(test_diff-loc3)*(scale2/scale3)\n",
    "    scaled_test_diff=test_diffs-np.mean(test_diff)\n",
    "    adjust_test_cumsum=np.cumsum(np.insert(scaled_test_diff,0,np.array(test_data.groupby('Date')['no_c_with_proba'].sum())[0]))\n",
    "\n",
    "\n",
    "    #beta-dist scaling\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    data2_scaled=scaler.fit_transform(np.array(train_data['energy_kwh']).reshape(-1,1)).flatten()\n",
    "    data2_scaled=np.clip(data2_scaled,1e-6,1-(1e-6))\n",
    "    a2,b2,loc2,scale2=beta.fit(data2_scaled,floc=0,fscale=1)\n",
    "\n",
    "    test_scaled=scaler.fit_transform(adjust_test_cumsum.reshape(-1,1)).flatten()\n",
    "    test_scaled=np.clip(test_scaled,1e-6,1-(1e-6))\n",
    "    a3,b3,loc3,scale3=beta.fit(test_scaled,floc=0,fscale=1)\n",
    "\n",
    "\n",
    "    test_cdf=beta.cdf(test_scaled,a3,b3)\n",
    "    y=beta.ppf(test_cdf,a2,b2)\n",
    "\n",
    "    x=y*(max(train_data['energy_kwh'])-min(train_data['energy_kwh']))+min(train_data['energy_kwh'])\n",
    "\n",
    "    pred_y=pd.DataFrame({\n",
    "    \"predict_energy_kwh\":x\n",
    "    })\n",
    "    pred_y.index=test_data[test_data['turbine_id']=='WTG01'].index\n",
    "    # pred_y.index=train_data['end_datetime']\n",
    "    pred_y.index.name='dt'\n",
    "\n",
    "    print(\"Prediction for\", locat, \"is done\")\n",
    "    return(pred_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excute the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/3559179510.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_data['binary_state'] = 1*(binary_data['state']>=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@ Transfoming Data @@@@@@\n",
      "@@@@@ Scaling Data @@@@@@\n",
      "Prediction for 영광풍력 is done\n"
     ]
    }
   ],
   "source": [
    "pred_yg=forecasting(\"영광풍력\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/3559179510.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  binary_data['binary_state'] = 1*(binary_data['state']>=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@ Transfoming Data @@@@@@\n",
      "@@@@@ Scaling Data @@@@@@\n",
      "Prediction for 경주풍력 is done\n"
     ]
    }
   ],
   "source": [
    "pred_gj=forecasting(\"경주풍력\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/3645417919.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission[submission['plant_name']=='경주풍력']['energy_kwh']=np.array(pred_gj['predict_energy_kwh'])\n",
      "/var/folders/tf/02_6lkvd73nbp9k5fyfj80fh0000gn/T/ipykernel_32159/3645417919.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission[submission['plant_name']=='영광풍력']['energy_kwh']=np.array(pred_yg['predict_energy_kwh'])\n"
     ]
    }
   ],
   "source": [
    "submission=pd.read_csv(SUBMISSION_PATH,encoding='euc-kr')\n",
    "submission[submission['plant_name']=='경주풍력']['energy_kwh']=np.array(pred_gj['predict_energy_kwh'])\n",
    "submission[submission['plant_name']=='영광풍력']['energy_kwh']=np.array(pred_yg['predict_energy_kwh'])\n",
    "submission['energy_kwh']=(pd.concat([pred_gj['predict_energy_kwh'],pred_yg['predict_energy_kwh']])).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('0. submission_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
